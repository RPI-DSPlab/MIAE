{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script is for processing predictions from attacks to further analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:00:18.599142Z",
     "start_time": "2024-06-12T21:00:18.588404Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "# add ../.. to the path (MIAE)\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from miae.utils.dataset_utils import dataset_split\n",
    "from experiment.models import get_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"select which task to perform\"\"\"\n",
    "task = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Show training and testing accuracy for all target we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data_path = '/data/public/comp_mia_data/repeat_exp_set'\n",
    "runs = [0, 1, 2, 3]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def accuracy(model, data, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.to(device)\n",
    "    data_loader = torch.utils.data.DataLoader(data, batch_size=128, shuffle=False)\n",
    "    with torch.inference_mode():\n",
    "        for images, labels in tqdm(data_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    top1_accuracy = correct / total\n",
    "    _, top3_predicted = torch.topk(outputs.data, 3, dim=1)\n",
    "    top3_correct = torch.sum(top3_predicted == labels.unsqueeze(1)).item()\n",
    "    top3_accuracy = top3_correct / total\n",
    "    return top1_accuracy, top3_accuracy\n",
    "\n",
    "\n",
    "def process_accuracy(arch, dataset, runs):\n",
    "    num_classes = 10 if dataset == \"cifar10\" else 100\n",
    "    input_size = 32\n",
    "    print (f\"Number of classes: {num_classes}\")\n",
    "    if arch == \"resnet56\":\n",
    "        target_model = get_model(\"resnet56\", num_classes=num_classes, input_size=input_size)\n",
    "    elif arch == \"vgg16\":\n",
    "        target_model = get_model(\"vgg16\", num_classes=num_classes, input_size=input_size)\n",
    "    elif arch == \"mobilenet\":\n",
    "        target_model = get_model(\"mobilenet\", num_classes=num_classes, input_size=input_size)\n",
    "    elif arch == \"wrn32_4\":\n",
    "        target_model = get_model(\"wrn32_4\", num_classes=num_classes, input_size=input_size)\n",
    "\n",
    "    train_accuracies = []\n",
    "    train_accuracies_top3 = []\n",
    "    test_accuracies = []\n",
    "    test_accuracies_top3 = []\n",
    "\n",
    "    for run in runs:  \n",
    "        target_path = os.path.join(data_path, f\"miae_experiment_aug_more_target_data_{run}/target\")\n",
    "        target_model_path = f\"{target_path}/target_models/{dataset}/{arch}/target_model_{arch}{dataset}.pkl\"\n",
    "        target_train_data_path = f\"{target_path}/{dataset}/target_trainset.pkl\"\n",
    "        target_test_data_path = f\"{target_path}/{dataset}/target_testset.pkl\"\n",
    "\n",
    "        target_model.load_state_dict(torch.load(target_model_path))\n",
    "        with open(target_train_data_path, 'rb') as f:\n",
    "            target_train_data = pickle.load(f)\n",
    "        with open(target_test_data_path, 'rb') as f:\n",
    "            target_test_data = pickle.load(f)\n",
    "\n",
    "        train_acc_ret = accuracy(target_model, target_train_data, device)\n",
    "        test_acc_ret = accuracy(target_model, target_test_data, device)\n",
    "\n",
    "        train_accuracies.append(train_acc_ret[0])\n",
    "        train_accuracies_top3.append(train_acc_ret[1])\n",
    "        test_accuracies.append(test_acc_ret[0])\n",
    "        test_accuracies_top3.append(test_acc_ret[1])\n",
    "\n",
    "    avg_train_accuracy = np.mean(train_accuracies)\n",
    "    std_train_accuracy = np.std(train_accuracies)\n",
    "    avg_train_accuracy_top3 = np.mean(train_accuracies_top3)\n",
    "    std_train_accuracy_top3 = np.std(train_accuracies_top3)\n",
    "    avg_test_accuracy = np.mean(test_accuracies)\n",
    "    std_test_accuracy = np.std(test_accuracies)\n",
    "    avg_test_accuracy_top3 = np.mean(test_accuracies_top3)\n",
    "    std_test_accuracy_top3 = np.std(test_accuracies_top3)\n",
    "    generalization_gap = avg_train_accuracy - avg_test_accuracy\n",
    "    generalization_gap_std = std_train_accuracy - std_test_accuracy\n",
    "\n",
    "\n",
    "    # average accuracy, std\n",
    "    print(f\"Average train accuracy: {avg_train_accuracy*100:.4f}% ± {std_train_accuracy*100:.4f}%\")\n",
    "    print(f\"Average test accuracy: {avg_test_accuracy*100:.4f}% ± {std_test_accuracy*100:.4f}%\")\n",
    "    print(f\"Generalization gap: {generalization_gap*100:.4f}% ± {generalization_gap_std*100:.4f}%\")\n",
    "\n",
    "    return avg_train_accuracy, std_train_accuracy, avg_train_accuracy_top3, std_train_accuracy_top3, avg_test_accuracy, std_test_accuracy, avg_test_accuracy_top3, std_test_accuracy_top3, generalization_gap, generalization_gap_std\n",
    "\n",
    "arch_list = [\"resnet56\", \"vgg16\", \"mobilenet\", \"wrn32_4\"]\n",
    "dataset_list = [\"cifar10\", \"cifar100\"]\n",
    "\n",
    "header = ['Architecture', 'Dataset', 'Avg Train Accuracy', 'Std Train Accuracy', 'Avg Test Accuracy', 'Std Test Accuracy', 'Generalization Gap', 'Generalization Gap Std']\n",
    "if task == 1:\n",
    "    with open(save_path, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "\n",
    "    for arch in arch_list:\n",
    "        for dataset in dataset_list:\n",
    "            print(f\"Processing {arch} on {dataset}\")\n",
    "            avg_train_accuracy, std_train_accuracy, avg_train_accuracy_top3, std_train_accuracy_top3, avg_test_accuracy, std_test_accuracy, avg_test_accuracy_top3, std_test_accuracy_top3, generalization_gap, generalization_gap_std = process_accuracy(arch, dataset, runs)\n",
    "            \n",
    "            # save to csv\n",
    "            save_path = f\"{data_path}/target_training_statsd.csv\"\n",
    "            with open(save_path, mode='a') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([arch, dataset, avg_train_accuracy, std_train_accuracy, avg_test_accuracy, std_test_accuracy, generalization_gap, generalization_gap_std])\n",
    "    print(f\"csv saved to {save_path}/miae_experiment_aug_more_target_data/target_training_statsd.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = '/data/public/comp_mia_data/miae_experiment_aug_more_target_data'\n",
    "target_data_path = ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-zhiqi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
